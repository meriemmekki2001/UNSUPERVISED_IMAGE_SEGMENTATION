import torch
import cv2
import math
from PIL import Image
import numpy as np
import urllib.request
from tqdm import tqdm
from torchvision import transforms


def create_adj(F, loss_type, threshold=0):
    if loss_type == "NCUT":
        W = F @ F.T
        # threshold
        W = W * (W > threshold)
        # norm
        W = W / W.max()
    elif loss_type == "DMON":
        F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)
        W = np.dot(F_norm, F_norm.T)
        W = np.where(W >= threshold, 1, 0).astype(np.float32)
        
    return W


def load_data(adj, node_feats):
    """
    Load data to pytorch-geometric data format
    @param adj: Adjacency metrix of a graph
    @param node_feats: Feature matrix of a graph
    @return: Graph in pytorch-geometric data format
    """
    node_feats = torch.from_numpy(node_feats)
    edge_index = torch.from_numpy(np.array(np.nonzero((adj > 0))))
    row, col = edge_index
    edge_weight = torch.from_numpy(adj[row, col])

    return node_feats, edge_index, edge_weight



def load_data_img(image, image_size):
    """
    Load image to model (Resize, To tensor, normalize)
    @param image: image 
    @param image_size: Output size for image
    @return: Resized image as a tensor and original image as a tuple
    """
    # Load image
    # pil_image = Image.open(chosen_dir).convert('RGB')
    #image = chosen_dir.numpy()

    pil_image = Image.fromarray(image).convert('RGB')

    # Define transformations
    prep = transforms.Compose([
        transforms.Resize(image_size, interpolation=transforms.InterpolationMode.LANCZOS),
        transforms.ToTensor(),
        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
    ])

    # Resized image tensor
    image_tensor = prep(pil_image)[None, ...]

    # To numpy array
    image = np.array(pil_image)

    return image_tensor, image



def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn("mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
                      "The distribution of values may be incorrect.",
                      stacklevel=2)

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        # Get upper and lower cdf values
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse cdf transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean, std
        tensor.mul_(std * math.sqrt(2.))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor


def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)


class DownloadProgressBar(tqdm):
    def update_to(self, b=1, bsize=1, tsize=None):
        if tsize is not None:
            self.total = tsize
        self.update(b * bsize - self.n)


def download_url(url, output_path):
    with DownloadProgressBar(unit='B', unit_scale=True,
                             miniters=1, desc=url.split('/')[-1]) as t:
        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)


def graph_to_mask(S, image_tensor, image):
    # Reshape clustered graph
    minus = 1  
    stride = 4 
    # -1 is needed only for stride==4 of descriptor extraction
    S = np.array(torch.reshape(S, (
        int(image_tensor.shape[2] // stride) - minus, int(image_tensor.shape[3] // stride) - minus)))

    # check if background is 0 and main object is 1 in segmentation map
    if (S[0][0] + S[S.shape[0] - 1][0] + S[0][S.shape[1] - 1] + S[S.shape[0] - 1][S.shape[1] - 1]) > 2:
        S = 1 - S

    # mask to original image size
    mask = cv2.resize(S.astype('float'), (image[:, :, 0].shape[1], image[:, :, 0].shape[0]),
                      interpolation=cv2.INTER_NEAREST)

    return mask



def apply_seg_map(img, seg, alpha):
    """
    Overlay segmentation map onto an image, the function is jited for performance.
    @param img: input image as numpy array
    @param seg: input segmentation map as a numpy array
    @param alpha: The opacity of the segmentation overlay, 0==transparent, 1==only segmentation map
    @return: segmented image as a numpy array
    """
    return ((seg * alpha*255)[:,:,None] + (img * (1 - alpha))).astype(np.uint8)




